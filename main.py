# PixivTags
# 
# Copyright (c) 2024-2025 zch9241. All rights reserved.
# 
# æœ¬è½¯ä»¶å—ä»¥ä¸‹ä½¿ç”¨æ¡æ¬¾çº¦æŸï¼š
# 1. ä»…é™ä¸ªäººåŠæ•™è‚²ç”¨é€”ï¼Œç¦æ­¢å•†ä¸šä½¿ç”¨
# 2. ç¦æ­¢æœªç»æˆæƒçš„è¥åˆ©æ€§ä¼ æ’­
# 3. å®Œæ•´æ¡æ¬¾è¯¦è§é¡¹ç›®æ ¹ç›®å½•LICENSEæ–‡ä»¶
# 
# å¦‚æœ‰ç–‘é—®è¯·è”ç³»ï¼š[zch2426936965@gmail.com]
# 

# TODO:
# ä¸ºæ’ç”»æ·»åŠ æ›´å¤šå…ƒæ•°æ®


# done:
# æ’ç”»æŸ¥è¯¢åŠŸèƒ½

# standard-libs
import asyncio
import inspect
import json
import logging
import os
import pdb
import sqlite3
import sys
import time
import traceback
from urllib import parse

# site-packages
from playwright.async_api import async_playwright
import playwright.async_api
from playwright.sync_api import sync_playwright
import psutil
from tqdm import tqdm
from tqdm.asyncio import tqdm as async_tqdm
from wcwidth import wcswidth
from win10toast import ToastNotifier


import search
from src import config


# å¸¸é‡åˆå§‹åŒ–
UID = config.UID
CHROME_PATH = config.CHROME_PATH
COOKIE_EXPIRED_TIME = config.COOKIE_EXPIRED_TIME

CWD = os.getcwd()
SQLPATH = CWD + r'\src\illdata.db'
COOKIE_PATH = CWD + r'\src\cookies.json'
COOKIE_TIME_PATH = CWD + r'\src\cookies_modify_time'
TAG_LOG_PATH = CWD + r'\logs\err_tags.log'

# äº¤äº’æ¨¡å¼
mode_select = """
\n===== PixivTags =====
è¯·é€‰æ‹©æ¨¡å¼: 
1 = æ›´æ–°tagsè‡³æœ¬åœ°æ•°æ®åº“
2 = åŸºäºæœ¬åœ°æ•°æ®åº“è¿›è¡Œæ’ç”»æœç´¢
3 = é€€å‡º
=====================\n
"""



# å·¥å…·å‡½æ•°
def format_string(s: str, target_width: int):
    """æ ¼å¼åŒ–å­—ç¬¦ä¸²ä¸ºå›ºå®šé•¿åº¦

    Args:
        s (str): è¦æ ¼å¼åŒ–çš„å­—ç¬¦ä¸²
        target_width (int): ç›®æ ‡é•¿åº¦

    Returns:
        (str): _description_
    """
    current_width = wcswidth(s)
    if current_width >= target_width:
        # æˆªæ–­é€»è¾‘
        res = []
        width = 0
        for c in s:
            w = wcswidth(c)
            if width + w > target_width:
                break
            res.append(c)
            width += w
        return ''.join(res) + ' ' * (target_width - width)
    else:
        return s + ' ' * (target_width - current_width)


def config_check(logger: logging.Logger) -> bool:
    """
    é…ç½®æ–‡ä»¶æ£€æŸ¥, è¿”å›Falseä¸ºå‡ºç°é”™è¯¯
    """
    logger.info('æ£€æŸ¥é…ç½®æ–‡ä»¶')
    if not all([type(UID) is str, 
            type(CHROME_PATH) is str, 
            type(COOKIE_EXPIRED_TIME) is int]):
        logger.error('config.pyæ•°æ®ç±»å‹æ ¡éªŒå¤±è´¥')
        return False
    if any([UID == '', CHROME_PATH == '', COOKIE_EXPIRED_TIME == 0]):
        logger.error('config.pyä¸­æœ‰å˜é‡å€¼æœªå¡«å†™')
        return False
    return True      


def handle_exception(logger: logging.Logger, in_bar = True, _async = False):
    """å¯¹æŠ›å‡ºé”™è¯¯çš„é€šç”¨å¤„ç†

    Args:
        logger (logging.Logger): logger
        in_bar (bool, optional): åŸå‡½æ•°ä¸­æ˜¯å¦æ‰“å°è¿›åº¦æ¡(tqdm)ï¼Œé˜²æ­¢è¾“å‡ºé”™ä¹±. Defaults to True.
        _async (bool, optional): åŸå‡½æ•°æ˜¯å¦ä¸ºå¼‚æ­¥å‡½æ•°ï¼Œå½“in_barä¸ºTrueæ—¶æœ‰æ•ˆ. Defaults to False.
    """
    exc_type, exc_value, tb = sys.exc_info()
    # è·å–å®Œæ•´çš„å †æ ˆè·Ÿè¸ªä¿¡æ¯
    tb_list = traceback.format_tb(tb)
    ex = "".join(tb_list)
    
    # åˆ¤æ–­è¾“å‡ºæ–¹å¼
    if in_bar is True and _async is False:
        tqdm.write(f'ERROR {exc_type.__name__}: {exc_value}')
        tqdm.write(f'ERROR {ex}')
    elif in_bar is True and _async is True:
        async_tqdm.write(f'ERROR {exc_type.__name__}: {exc_value}')
        async_tqdm.write(f'ERROR {ex}')
    else:
        logger.error(f'{exc_type.__name__}: {exc_value}')
        logger.error(ex)


# è·å–cookies
def get_cookies(logger: logging.Logger, rtime: int, forced = False):
    """è·å–Google Chromeçš„cookies

    Args:
        rtime (int): cookieæ›´æ–°é—´éš”
        forced (bool): æ˜¯å¦å¼ºåˆ¶æ›´æ–°
    """
    # åˆ¤æ–­æ˜¯å¦éœ€è¦æ›´æ–°cookies
    logger.info('éªŒè¯cookieæœ‰æ•ˆæ€§')
    
    with open(COOKIE_TIME_PATH, 'r') as f:
        data = f.read()
        if data != '':
            modify_time = float(data)
        else:
            modify_time = 0
    relative_time = time.time() - modify_time
    
    if (relative_time < rtime and 
        relative_time > 0 and 
        forced is False):
        
        logger.info(f'æ— éœ€æ›´æ–°cookies: è·ä¸Šæ¬¡æ›´æ–° {relative_time} ç§’')
    
    else:
        logger.info(f'éœ€è¦æ›´æ–°cookies: è·ä¸Šæ¬¡æ›´æ–° {relative_time} ç§’')

        # åˆ¤æ–­Google Chromeæ˜¯å¦åœ¨è¿è¡Œï¼Œå¦‚æœåœ¨chromeè¿è¡Œæ—¶ä½¿ç”¨playwrightå°†ä¼šæŠ¥é”™
        def find_process(name):
            for proc in psutil.process_iter(['pid', 'name']):
                try:
                    if name.lower() in proc.info['name'].lower():
                        return proc
                except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                    pass
            return None

        def kill_process(name):
            proc = find_process(name)
            while proc:
                logger.info(f"æ‰¾åˆ° chrome è¿›ç¨‹ (name: {proc.info['name']}, PID: {proc.info['pid']})")
                logger.info("è¯·ç»“æŸè¿›ç¨‹ï¼Œå¦åˆ™cookiesæ— æ³•æ­£å¸¸è·å–")
                
                os.system('pause')
                proc = find_process(name)
        kill_process("chrome.exe")

        # è·å–cookies
        with sync_playwright() as p:
            browser = p.chromium.launch_persistent_context(headless=True,
                executable_path=r'C:\Program Files\Google\Chrome\Application\chrome.exe',
                user_data_dir=os.path.expanduser(
                    os.path.join(os.environ['LOCALAPPDATA'], r'Google\Chrome\User Data'))
                )
            
            with open(r'.\src\cookies.json','w') as f:
                state = {"cookies": browser.cookies('https://www.pixiv.net'), "origins": []}
                f.write(json.dumps(state))
            # å…³é—­æµè§ˆå™¨
            browser.close()
        logger.info('cookieså·²è·å–')
        
        # æ›´æ–°è·å–cookieçš„æ—¶é—´
        with open(COOKIE_TIME_PATH, "w") as f:
            f.write(str(time.time()))


# æ•°æ®åº“ç›¸å…³æ“ä½œ
def dbexecute(query: str, 
              params: tuple|list[tuple]=None, 
              many=False):  
    """æ•°æ®åº“æ“ä½œ

    Args:
        query (str): sqlå‘½ä»¤
        params (tuple|list[tuple], optional): æŸ¥è¯¢å‚æ•°. Defaults to None.
        many (bool, optional): æ˜¯å¦å¯¹å¤šè¡Œæ•°æ®è¿›è¡Œæ“ä½œ,è‹¥å°†å‚æ•°è®¾ä¸ºTrue,è¯·ç¡®ä¿ä¼ å…¥çš„paramsä¸ºlist[tuple]ç±»å‹. Defaults to False.

    Returns:
        list|None: æŸ¥è¯¢ç»“æœï¼ˆè‹¥æœ‰ï¼‰
    """
    res = ''
    conn = sqlite3.connect(SQLPATH)  
    cursor = conn.cursor()  
    try:
        if (many is True 
            and type(params) == list 
            and all(isinstance(item, tuple) for item in params)):   # éªŒè¯list[tuple]
            cursor.executemany(query, params or ())
        elif type(params) == tuple or params is None:
            cursor.execute(query, params or ()) 
        else:
                raise Exception("ä¼ å…¥çš„paramsç±»å‹æ ¡éªŒé”™è¯¯")
        conn.commit()  
        res = cursor.fetchall()
    except Exception:
        handle_exception(logger, inspect.currentframe().f_code.co_name)
        conn.rollback()  
    finally:  
        cursor.close()  
        conn.close()  
    if res != '':
        return res
    else:
        return None


# è·å–pixivä¸Šçš„tagså¹¶ç¿»è¯‘
def analyse_bookmarks(logger: logging.Logger, rest_flag=2, limit=100) -> list:
    """è§£æç”¨æˆ·bookmarksæ¥å£URL

    æ¥å£åç§°: https://www.pixiv.net/ajax/user/{UID}/illusts/bookmarks?tag={}&offset={}&limit={}&rest={}&lang={}
    
    Args:
        rest_flag (int, optional): æ’ç”»çš„å¯è§æ€§ (0=å…¬å¼€, 1=ä¸å…¬å¼€, 2=å…¨éƒ¨). Defaults to 2.
        limit (int, optional): ä¸€ä¸ªæ¥å£URLæˆªå–çš„æ’ç”»æ•°ç›®, å®æµ‹æœ€å¤§å€¼ä¸º100. Defaults to 100.

    Returns:
        list: æ¥å£URL
    """

    logger.info('æ­£åœ¨è¿è¡Œ')

    rest_dict = {0: ['show'], 1: ['hide'], 2: ['show', 'hide']}
    rest = rest_dict[rest_flag]

    # è§£æç”¨æˆ·bookmarkçš„æ’ç”»æ•°é‡
    url_show = f'https://www.pixiv.net/ajax/user/{UID}/illusts/bookmarks?tag=&offset=0&limit=1&rest=show&lang=zh'
    url_hide = f'https://www.pixiv.net/ajax/user/{UID}/illusts/bookmarks?tag=&offset=0&limit=1&rest=hide&lang=zh'

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True,executable_path=CHROME_PATH)
        context = browser.new_context(storage_state=COOKIE_PATH)
        session = context.request
        
        resp = session.get(url_show).json()
        total_show = resp['body']['total']

        resp = session.get(url_hide).json()
        total_hide = resp['body']['total']
        
        browser.close()

    logger.info(f'è§£æbookmarkså®Œæˆ, å…¬å¼€æ•°é‡: {total_show}, ä¸å…¬å¼€æ•°é‡: {total_hide}')


    # è®¡ç®—è¯·æ±‚URL
    urls = []
    for r in rest:
        if r == 'show':
            total = total_show
            k = total//limit            # æ•´æ­¥æ­¥æ•°
            l = total - k*limit + 1     # å‰©ä½™éƒ¨åˆ†å¯¹åº”çš„limit
            s = 0                       # è®¡æ•°å™¨
            while k > s:
                urls.append(
                    f'https://www.pixiv.net/ajax/user/{UID}/illusts/bookmarks?tag=&offset={s*limit}&limit={limit}&rest=show&lang=zh')
                s += 1
            
            urls.append(
                f'https://www.pixiv.net/ajax/user/{UID}/illusts/bookmarks?tag=&offset={s*limit}&limit={l}&rest=show&lang=zh')
        elif r == 'hide':
            total = total_hide
            k = total//limit            # æ•´æ­¥æ­¥æ•°
            l = total - k*limit + 1     # å‰©ä½™éƒ¨åˆ†å¯¹åº”çš„limit
            s = 0                       # è®¡æ•°å™¨
            while k > s:
                urls.append(
                    f'https://www.pixiv.net/ajax/user/{UID}/illusts/bookmarks?tag=&offset={s*limit}&limit={limit}&rest=hide&lang=zh')
                s += 1
            
            urls.append(
                f'https://www.pixiv.net/ajax/user/{UID}/illusts/bookmarks?tag=&offset={s*limit}&limit={l}&rest=hide&lang=zh')

    logger.info(f'è§£ææ¥å£URLå®Œæˆ, æ•°é‡: {len(urls)}')
    return urls


async def analyse_illusts_worker(session: playwright.async_api.APIRequestContext, 
                                 queue: asyncio.Queue, 
                                 illdatas: list,
                                 ignores: list, 
                                 pbar: async_tqdm, 
                                 retries = 5):
    while True:
        url = await queue.get()
        try:
            for attempt in range(retries):
                try:
                    resp = await session.get(url)
                    if resp.status == 429:
                        wait_time = 2 ** (attempt + 1)
                        async_tqdm.write(f"è§¦å‘é™æµ [{url}]ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                        await asyncio.sleep(wait_time)
                        continue
                    
                    resp = await resp.json()
                    illdata_ = resp['body']['works']     # ä¸€ä¸ªæ¥å£urlæ‰€è·å–åˆ°çš„æ‰€æœ‰æ’ç”»ä¿¡æ¯
                    for illdata in illdata_:
                        if illdata['isMasked'] is True:
                            ignores.append(illdata['id'])
                        else:
                            illdatas.append(illdata)    # æ±‡æ€»åˆ°ä¸»åˆ—è¡¨
                    break
                except Exception as e:
                    async_tqdm.write(f"è¯·æ±‚å¤±è´¥ [{url}]: {sys.exc_info()}")
                    await asyncio.sleep(0.5 * (attempt + 1))

            pbar.update(1)
        except Exception as e:
            async_tqdm.write(sys.exc_info())
        finally:
            queue.task_done()
    
async def analyse_illusts_main(logger: logging.Logger, bookmark_urls: list, max_concurrency = 3):
    """è·å–bookmarkä¸­æ¯å¼ æ’ç”»çš„æ•°æ®

    Args:
        bookmark_urls (list): ç”¨æˆ·çš„å…¨éƒ¨bookmarkçš„æ¥å£url
        max_concurrency (int, optional): é¡¾åæ€ä¹‰. Defaults to 3.

    Returns:
        list: æ¯å¼ æ’ç”»çš„æ•°æ®
    """
    logger.info('æ­£åœ¨è¿è¡Œ')
    
    illdatas = []    # åŒ…å«æ’ç”»ä¿¡æ¯çš„åˆ—è¡¨
    ignores = []     # å› æ•…æ— æ³•è·å–æ’ç”»ä¿¡æ¯çš„è®¡æ•°å™¨(ä»¥åˆ—è¡¨å½¢å¼å­˜å‚¨)

    async with async_playwright() as p:
        browser = await p.chromium.launch(
            headless=True,
            executable_path=CHROME_PATH
        )
        
        context = await browser.new_context(storage_state=COOKIE_PATH)
        session = context.request
        
        queue = asyncio.Queue()
        for url in bookmark_urls:
            await queue.put(url)
        
        with async_tqdm(total = len(bookmark_urls), desc = 'è·å–æ’ç”»ä¿¡æ¯') as pbar:
            workers = [
                asyncio.create_task(analyse_illusts_worker(session, queue, illdatas, ignores, pbar))
                for _ in range(min(max_concurrency, len(bookmark_urls)))
            ]

            await queue.join()
            for w in workers:
                w.cancel()
        await context.close()
        await browser.close()
        
    logger.info(f'æ‰€æœ‰æ’ç”»ä¿¡æ¯è·å–å®Œæˆï¼Œé•¿åº¦: {len(illdatas)} å¿½ç•¥æ•°é‡: {len(ignores)}')
    return illdatas


def commit_illust_data(logger: logging.Logger, illdatas: list):
    """æäº¤æ’ç”»åŸºæœ¬æ•°æ®

    Args:
        illdatas (list): æ’ç”»æ•°æ®ï¼Œç”±analyse_illustsè·å–
    """
    logger.info('æ­£åœ¨è¿è¡Œ')

    # æ’ç”»åŸºæœ¬ä¿¡æ¯ (é™¤äº†tags)
    basic_illdatas = [(int(illdata['id']),
                 int(illdata['userId']),
                 illdata['title'], 
                 int(illdata['bookmarkData']['private'])   # æ­¤æ•°æ®åŸæœ¬æ˜¯å¸ƒå°”å€¼
                 )
                for illdata in illdatas]
    
    sql = '''
    INSERT INTO illusts (pid, author_id, title, is_private) VALUES (?, ?, ?, ?)
    ON CONFLICT(pid) DO UPDATE
    SET 
        author_id = excluded.author_id,
        title = excluded.title,
        is_private = excluded.is_private;
    '''
    
    
    with sqlite3.connect(SQLPATH) as conn:
        cursor = conn.cursor()
        cursor.executemany(sql, basic_illdatas)
        
        # æ’å…¥æ’ç”»tags
        for illdata in illdatas:
            pid = int(illdata['id'])
            for tag in illdata['tags']:
                cursor.execute('INSERT OR IGNORE INTO tags (jptag) VALUES (?)', (tag,))
                # è·å–tag_id
                cursor.execute('SELECT tag_id FROM tags WHERE jptag = (?)', (tag,))
                tag_id = cursor.fetchone()[0]
                # æ’å…¥å…³è”å…³ç³»
                cursor.execute('INSERT OR IGNORE INTO illust_tags (pid, tag_id) VALUES (?, ?)', (pid, tag_id))

        conn.commit()
        cursor.close()

    logger.info('æäº¤å®Œæˆ')


async def fetch_tag(session: playwright.async_api.APIRequestContext, 
                    tag: str, 
                    retries=5) -> tuple[str, dict]:
    encoded_tag = parse.quote(tag, safe = '')
    url = f"https://www.pixiv.net/ajax/search/tags/{encoded_tag}?lang=zh"
    for attempt in range(retries):
        try:
            response = await session.get(url)
            
            if response.status == 429:
                wait_time = 2 ** (attempt + 1)
                async_tqdm.write(f"è§¦å‘é™æµ [{tag}]ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                await asyncio.sleep(wait_time)
                continue
                
            return (tag, await response.json())
            
        except Exception as e:
            async_tqdm.write(f"è¯·æ±‚å¤±è´¥ [{tag}]: {sys.exc_info()}")
            if attempt == retries - 1:  # è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°
                return (tag, {"error": sys.exc_info()})
            await asyncio.sleep(0.5 * (attempt + 1))

async def fetch_tag_worker(session: playwright.async_api.APIRequestContext, 
                           queue: asyncio.Queue, 
                           results: list, 
                           pbar: async_tqdm):
    while True:
        jptag = await queue.get()
        try:
            # æ ¼å¼åŒ–pbaræè¿°
            match jptag:
                case str():
                    desc = format_string(f"è·å–tag: {jptag}", 30)
                case _:
                    raise Exception(f'å˜é‡jptagä¸ºä¸æ”¯æŒçš„ç±»å‹ {type(jptag)}')
            pbar.set_description(desc)
            result: tuple[str, dict] = await fetch_tag(session, jptag)
            results.append(result)
            pbar.update(1)
        except Exception as e:
            handle_exception(logger, inspect.currentframe().f_code.co_name, in_bar=True, async_=True)
        finally:
            queue.task_done()

async def fetch_translated_tag_main(logger: logging.Logger, 
                                    priority: list = ['zh', 'en', 'zh_tw'], 
                                    max_concurrency = 20) -> tuple[list, list]:
    """è·å–pixivä¸Šçš„tagç¿»è¯‘

    Args:
        logger (logging.Logger): _description_
        priority (list, optional): ç¿»è¯‘è¯­è¨€ä¼˜å…ˆçº§åˆ—è¡¨ï¼ˆä¼˜å…ˆçº§é€’å‡ï¼‰. Defaults to ['zh', 'en', 'zh_tw'].
        max_concurrency (int, optional): æœ€å¤§åç¨‹æ•°é‡. Defaults to 20.

    Returns:
        tuple[list, list]: åŒ…å«ä¸€ä¸ªjptag-transtagçš„å­—å…¸çš„åˆ—è¡¨ï¼Œä»¥åŠä¸€ä¸ªæœªç¿»è¯‘æˆåŠŸçš„tagçš„åˆ—è¡¨
    """
    logger.info('æ­£åœ¨è¿è¡Œ')
    # åªæ‰¾å‡ºæœªç¿»è¯‘çš„tag
    res = dbexecute('''
                SELECT jptag FROM tags WHERE transtag is NULL
                ''')

    jptags = [r[0] for r in res]
    logger.info(f'å·²ä»æ•°æ®åº“è·å– {len(jptags)} ä¸ªtag')


    async with async_playwright() as p:
        browser = await p.chromium.launch(
            headless=True,
            executable_path=CHROME_PATH
        )
        
        context = await browser.new_context(storage_state=COOKIE_PATH)
        session = context.request
        
        queue = asyncio.Queue()
        for jptag in jptags:
            await queue.put(jptag)
        
        results = []
        
        with async_tqdm(total=len(jptags), desc="é‡‡é›†è¿›åº¦") as pbar:
            workers = [
                asyncio.create_task(fetch_tag_worker(session, queue, results, pbar))
                for _ in range(min(max_concurrency, len(jptags)))
            ]

            await queue.join()
            
            for w in workers:
                w.cancel()
        
        await context.close()
        await browser.close()
    
    translation_results = []
    tags_caught_exception = []
    for tag, resp in results:
        if resp['error'] is not False:
            tags_caught_exception.append(tag)
        else:
            tagTranslation = resp['body']['tagTranslation']
            transtag = ''
            if tagTranslation == []:
                # print(tagTranslation)
                # logger.info(f'æ— tag {tag} çš„ç¿»è¯‘')
                result = {tag: tag}
            else:
                trans: dict = tagTranslation[tag]  # åŒ…å«æ‰€æœ‰ç¿»è¯‘è¯­è¨€çš„dict
                lans = trans.keys()
                for l in priority:
                    if l in lans and trans[l] != '':
                        transtag = trans[l]
                        break
                if transtag == '':
                    av = []
                    for available in trans.values():
                        if available != '':
                            # æ˜¯å¦æœ‰ä¸ç”¨éå†çš„æ–¹æ³•?
                            [av.append(_) for _ in trans.keys() if trans[_] == available]
                    # logger.info(f'tag {tag} æ— ç›®æ ‡è¯­è¨€çš„ç¿»è¯‘ & å¯ç”¨çš„è¯­è¨€ {av}')
                    result = {tag: tag}
                else:
                    result = {tag: transtag}
            translation_results.append(result)
    
    # åœ¨æ–‡ä»¶ä¸­è®°å½•ç¿»è¯‘å¤±è´¥çš„tags
    if len(tags_caught_exception) > 0:
        with open(TAG_LOG_PATH, 'a', encoding = 'utf-8') as f:
            f.write(str(time.strftime("%b %d %Y %H:%M:%S", time.localtime())))
            f.write(f'è¯·æ±‚tag {tags_caught_exception}')
            f.write('\n')
        logger.warning('æœ‰éƒ¨åˆ†tagæœªèƒ½ç¿»è¯‘ï¼Œå¤±è´¥çš„ç»“æœå·²å†™å…¥log')
    
    logger.info(f'tagç¿»è¯‘æˆåŠŸï¼ŒæˆåŠŸ {len(translation_results)} ä¸ª, å¤±è´¥ {len(tags_caught_exception)} ä¸ª')
    return translation_results, tags_caught_exception


def commit_translated_tags(logger: logging.Logger, translated_tags: list):
    """æäº¤ç¿»è¯‘åçš„tags

    Args:
        translated_tags (list): fetch_translated_tagsè·å–çš„ç¿»è¯‘åtagåˆ—è¡¨
    """
    logger.info('æ­£åœ¨è¿è¡Œ')
    jpTags_transTags = [(list(jptag_transtag.keys())[0], 
                         list(jptag_transtag.values())[0])
                        for jptag_transtag in translated_tags]  # è½¬æ¢tagç¿»è¯‘å¯¹åº”å…³ç³»ä¸ºå…ƒç»„
    with sqlite3.connect(SQLPATH) as conn:
        cursor = conn.cursor()
        cursor.executemany('UPDATE OR IGNORE tags SET transtag = ? WHERE jptag = ?', jpTags_transTags)
        cursor.execute("UPDATE tags SET transtag = NULL WHERE transtag == 'None'")
        conn.commit()
        cursor.close()
    
    logger.info('ç¿»è¯‘åçš„tagå·²æäº¤')


def main():
    while True:
        print(mode_select)
        mode = input('æ¨¡å¼ = ')
        if mode == '1':
            start = time.time()
            get_cookies(logger, rtime=COOKIE_EXPIRED_TIME)
            URLs = analyse_bookmarks(logger)
            
            # debug:
            # URLs = ['https://www.pixiv.net/ajax/user/71963925/illusts/bookmarks?tag=&offset=187&limit=1&rest=hide']

            
            illdatas = asyncio.run(analyse_illusts_main(logger, URLs))

            # debug:
            #illdata = [{'id': '79862254', 'title': 'ã‚¿ã‚·ãƒ¥ã‚±ãƒ³ãƒˆâ™¡', 'illustType': 0, 'xRestrict': 0, 'restrict': 0, 'sl': 2, 'url': 'https://i.pximg.net/c/250x250_80_a2/img-master/img/2020/03/03/09/31/57/79862254_p0_square1200.jpg', 'description': '', 'tags': ['ã‚¿ã‚·ãƒ¥ã‚±ãƒ³ãƒˆ', 'ã‚¢ã‚ºãƒ¼ãƒ«ãƒ¬ãƒ¼ãƒ³', 'ã‚¿ã‚·ãƒ¥ã‚±ãƒ³ãƒˆ(ã‚¢ã‚ºãƒ¼ãƒ«ãƒ¬ãƒ¼ãƒ³)', 'ã‚¤ãƒ©ã‚¹ãƒˆ', 'é¯›ç„¼ã', 'ã‚¢ã‚ºãƒ¼ãƒ«ãƒ¬ãƒ¼ãƒ³10000userså…¥ã‚Š'], 'userId': '9216952', 'userName': 'AppleCaramel', 'width': 1800, 'height': 2546, 'pageCount': 1, 'isBookmarkable': True, 'bookmarkData': {'id': '25192310391', 'private': False}, 'alt': '#ã‚¿ã‚·ãƒ¥ã‚±ãƒ³ãƒˆ ã‚¿ã‚·ãƒ¥ã‚±ãƒ³ãƒˆâ™¡ - AppleCaramelçš„æ’ç”»', 'titleCaptionTranslation': {'workTitle': None, 'workCaption': None}, 'createDate': '2020-03-03T09:31:57+09:00', 'updateDate': '2020-03-03T09:31:57+09:00', 'isUnlisted': False, 'isMasked': False, 'aiType': 0, 'profileImageUrl': 'https://i.pximg.net/user-profile/img/2022/10/24/02/12/49/23505973_7d9aa88560c5115b85cc29749ed40e28_50.jpg'},
            #{'id': '117717637', 'title': 'ãŠã—ã”ã¨çµ‚ã‚ã‚Šã«ãƒã‚°ã—ã¦ãã‚Œã‚‹å¤©ä½¿', 'illustType': 0, 'xRestrict': 0, 'restrict': 0, 'sl': 4, 'url': 'https://i.pximg.net/c/250x250_80_a2/custom-thumb/img/2024/04/10/17/30/02/117717637_p0_custom1200.jpg', 'description': '', 'tags': ['ã‚ªãƒªã‚¸ãƒŠãƒ«', 'å¥³ã®å­', 'ç·‘é«ª', 'å¤©ä½¿', 'ãƒã‚°', 'å·¨ä¹³', 'ã±ã‚“ã¤', 'ã‚ªãƒªã‚¸ãƒŠãƒ«1000userså…¥ã‚Š'], 'userId': '29164302', 'userName': 'ç·‘é¢¨ãƒãƒ«ãƒˆğŸŒ¿', 'width': 1296, 'height': 1812, 'pageCount': 1, 'isBookmarkable': True, 'bookmarkData': {'id': '25109862018', 'private': False}, 'alt': '#ã‚ªãƒªã‚¸ãƒŠãƒ« ãŠã—ã”ã¨çµ‚ã‚ã‚Šã«ãƒã‚°ã—ã¦ãã‚Œã‚‹å¤©ä½¿ - ç·‘é¢¨ãƒãƒ«ãƒˆğŸŒ¿çš„æ’ç”»', 'titleCaptionTranslation': {'workTitle': None, 'workCaption': None}, 'createDate': '2024-04-10T17:30:02+09:00', 'updateDate': '2024-04-10T17:30:02+09:00', 'isUnlisted': False, 'isMasked': False, 'aiType': 1, 'profileImageUrl': 'https://i.pximg.net/user-profile/img/2024/01/25/15/56/10/25434619_c70d86172914664ea2b15cec94bc0afd_50.png'},
            #{'id': '84450882', 'title': 'ãƒã‚³è€³å¢¨ã¡ã‚ƒã‚“ğŸˆ', 'illustType': 0, 'xRestrict': 0, 'restrict': 0, 'sl': 2, 'url': 'https://i.pximg.net/c/250x250_80_a2/img-master/img/2020/09/18/19/44/35/84450882_p0_square1200.jpg', 'description': '', 'tags': ['å½¼å¥³ã€ãŠå€Ÿã‚Šã—ã¾ã™', 'ã‹ã®ã‹ã‚Š', 'æ¡œæ²¢å¢¨', 'çŒ«', 'çŒ«è€³', 'åˆ¶æœ', 'ç™½ãƒ‹ãƒ¼ã‚½', 'æ‹¾ã£ã¦ãã ã•ã„', 'å½¼å¥³ã€ãŠå€Ÿã‚Šã—ã¾ã™5000userså…¥ã‚Š'], 'userId': '38436050', 'userName': 'ã‚†ãã†ãªãï¼ åœŸæ›œæ±ã‚¹88a', 'width': 2894, 'height': 4093, 'pageCount': 1, 'isBookmarkable': True, 'bookmarkData': {'id': '24948220443', 'private': False}, 'alt': '#å½¼å¥³ã€ãŠå€Ÿã‚Šã—ã¾ã™ ãƒã‚³è€³å¢¨ã¡ã‚ƒã‚“ğŸˆ - ã‚†ãã†ãªãï¼ åœŸæ›œæ±ã‚¹88açš„æ’ç”»', 'titleCaptionTranslation': {'workTitle': None, 'workCaption': None}, 'createDate': '2020-09-18T19:44:35+09:00', 'updateDate': '2020-09-18T19:44:35+09:00', 'isUnlisted': False, 'isMasked': False, 'aiType': 0, 'profileImageUrl': 'https://i.pximg.net/user-profile/img/2020/02/22/00/11/25/17966339_a51ca7e8a3aca581fc87021488e21479_50.jpg'},
            #]


            commit_illust_data(logger, illdatas)


            trans, _ = asyncio.run(fetch_translated_tag_main(logger))
            # debug:
            # trans = [{'ã‚ªãƒªã‚¸ãƒŠãƒ«': 'åŸåˆ›'}, {'æ‹¾ã£ã¦ãã ã•ã„': 'None'}, {'é¯›ç„¼ã': 'None'}, {'ã‹ã®ã‹ã‚Š': 'Rent-A-Girlfriend'}, {'å½¼å¥³ã€ãŠå€Ÿã‚Šã—ã¾ã™5000userså…¥ã‚Š': 'ç§Ÿå€Ÿå¥³å‹5000æ”¶è—'}, {'å¥³ã®å­': 'å¥³å­©å­'}, {'æ¡œæ²¢å¢¨': 'æ¨±æ³½å¢¨'}, {'ç·‘é«ª': 'green hair'}, {'çŒ«è€³': 'cat ears'}, {'çŒ«': 'cat'}, {'å¤©ä½¿': 'angel'}, {'ç™½ãƒ‹ãƒ¼ã‚½': 'ç™½è‰²è¿‡è†è¢œ'}, {'åˆ¶æœ': 'uniform'}, {'å½¼å¥³ã€ãŠå€Ÿã‚Šã—ã¾ã™': 'Rent-A-Girlfriend'}, {'ã‚¢ã‚ºãƒ¼ãƒ«ãƒ¬ãƒ¼ãƒ³': 'ç¢§è“èˆªçº¿'}, {'ã±ã‚“ã¤': 'èƒ–æ¬¡'}, {'ã‚ªãƒªã‚¸ãƒŠãƒ«1000userså…¥ã‚Š': 'åŸåˆ›1000usersåŠ å…¥ä¹¦ç±¤'}, {'ã‚¿ã‚·ãƒ¥ã‚±ãƒ³ãƒˆ': 'å¡”ä»€å¹²'}, {'ãƒã‚°': 'æ‹¥æŠ±'}, {'ã‚¿ã‚·ãƒ¥ã‚±ãƒ³ãƒˆ(ã‚¢ã‚ºãƒ¼ãƒ«ãƒ¬ãƒ¼ãƒ³)': 'å¡”ä»€å¹²ï¼ˆç¢§è“èˆªçº¿ï¼‰'}, {'ã‚¢ã‚ºãƒ¼ãƒ«ãƒ¬ãƒ¼ãƒ³10000userså…¥ã‚Š': 'ç¢§è“èˆªçº¿10000æ”¶è—'}, {'å·¨ä¹³': 'large breasts'}, {'ã‚¤ãƒ©ã‚¹ãƒˆ': 'æ’ç”»'}]


            commit_translated_tags(logger, trans)

            end = time.time()

            toaster.show_toast('PixivTags', f'å·²æ›´æ–°tagsè‡³æœ¬åœ°æ•°æ®åº“, è€—æ—¶ {round(end-start, 2)} s', duration = 10)
        
        elif mode == "2":
            search.main(SQLPATH)

        elif mode == '3':
            logger.info('ç¨‹åºé€€å‡º')
            break
        else:
            print(f'æœªçŸ¥çš„æŒ‡ä»¤ {mode}')
        print('')

if __name__ == "__main__":
    # æ—¥å¿—åˆå§‹åŒ–
    logger = logging.getLogger('logger')
    handler = logging.StreamHandler()
    logger.setLevel(logging.DEBUG)
    handler.setLevel(logging.DEBUG)
    formatter = logging.Formatter(
        "[%(asctime)s %(name)s %(thread)d %(funcName)s] %(levelname)s %(message)s")
    handler.setFormatter(formatter)
    logger.addHandler(handler)

    # Toaståˆå§‹åŒ–
    toaster = ToastNotifier()

    # æ•°æ®åº“åˆå§‹åŒ–
    with sqlite3.connect(SQLPATH) as conn:
        cursor = conn.cursor()  

        # ä½œå“ä¸»è¡¨
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS illusts (
            pid INTEGER PRIMARY KEY,
            author_id INTEGER,
            title TEXT,
            created_at TEXT DEFAULT (datetime('now', 'localtime')),
            is_private INTEGER DEFAULT 0
        )''')

        # æ ‡ç­¾å­—å…¸è¡¨
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS tags (
            tag_id INTEGER PRIMARY KEY AUTOINCREMENT,
            jptag TEXT UNIQUE,
            transtag TEXT
        )''')

        # ä½œå“-æ ‡ç­¾å…³è”è¡¨
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS illust_tags (
            pid INTEGER,
            tag_id INTEGER,
            FOREIGN KEY(pid) REFERENCES illusts(pid),
            FOREIGN KEY(tag_id) REFERENCES tags(tag_id),
            UNIQUE(pid, tag_id)
        )''')

        # åˆ›å»ºç´¢å¼•
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_jptag ON tags(jptag)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_transtag ON tags(transtag)')
        conn.commit()
        cursor.close()


    if (status:=config_check(logger)) == True:
        main()
    else:
        logger.info('è¯·å‰å¾€ src/config.py ä¿®æ”¹é…ç½®æ–‡ä»¶')
