# PixivTags
# 
# Copyright (c) 2024-2025 zch9241. All rights reserved.
# 
# æœ¬è½¯ä»¶å—ä»¥ä¸‹ä½¿ç”¨æ¡æ¬¾çº¦æŸï¼š
# 1. ä»…é™ä¸ªäººåŠæ•™è‚²ç”¨é€”ï¼Œç¦æ­¢å•†ä¸šä½¿ç”¨
# 2. ç¦æ­¢æœªç»æˆæƒçš„è¥åˆ©æ€§ä¼ æ’­
# 3. å®Œæ•´æ¡æ¬¾è¯¦è§é¡¹ç›®æ ¹ç›®å½•LICENSEæ–‡ä»¶
# 
# å¦‚æœ‰ç–‘é—®è¯·è”ç³»ï¼š[zch2426936965@gmail.com]
# 

# TODO:
# ä¼˜åŒ–æŸ¥è¯¢åŠŸèƒ½
# ä¸ºæ’ç”»æ·»åŠ æ›´å¤šå…ƒæ•°æ®


# done:
# çˆ¬è™«å‡½æ•°ä½¿ç”¨sessionï¼Œæé«˜æ•ˆç‡
# éƒ¨åˆ†çˆ¬è™«æ”¹ä¸ºå¼‚æ­¥ï¼Œæé«˜æ•ˆç‡
# ä¿®æ”¹ç‰ˆæƒå£°æ˜
# æ•°æ®åº“ç»“æ„ä¿®æ”¹
# æ•°æ®åº“äº¤äº’å‡½æ•°ä¿®æ”¹ï¼ˆå•çº¿ç¨‹ï¼‰


# standard-libs
import asyncio
import base64
from concurrent.futures import ThreadPoolExecutor, wait, as_completed, ALL_COMPLETED
import datetime
from difflib import get_close_matches
import inspect
import json
import logging
import os
import pdb
import re
import shutil
import sqlite3
import sys
import threading
import time
import traceback
from urllib import parse

# site-packages
import pandas as pd
from playwright.async_api import async_playwright
import playwright.async_api
from playwright.sync_api import sync_playwright
import psutil
from tqdm import tqdm
from tqdm.asyncio import tqdm as async_tqdm
from win10toast import ToastNotifier



from src import config


# å¸¸é‡åˆå§‹åŒ–
ANALYSE_ILLUST_THREADS = config.ANALYSE_ILLUST_THREADS
WRITERAW_TO_DB_THREADS = config.WRITERAW_TO_DB_THREADS
WRITE_TAGS_TO_DB_THREADS = config.WRITE_TAGS_TO_DB_THREADS
FETCH_TRANSLATED_TAG_THREADS = config.FETCH_TRANSLATED_TAG_THREADS
WRITE_TRANSTAGS_TO_DB_THREADS = config.WRITE_TRANSTAGS_TO_DB_THREADS
TRANSTAG_RETURN_THREADS = config.TRANSTAG_RETURN_THREADS
UID = config.UID
CHROME_PATH = config.CHROME_PATH
COOKIE_EXPIRED_TIME = config.COOKIE_EXPIRED_TIME

CWD = os.getcwd()
SQLPATH = CWD + r'\src\illdata.db'
COOKIE_PATH = CWD + r'\src\cookies.json'
COOKIE_TIME_PATH = CWD + r'\src\cookies_modify_time'
TAG_LOG_PATH = CWD + r'\logs\tag\content.log'

# äº¤äº’æ¨¡å¼
mode_select = """
è¯·é€‰æ‹©æ¨¡å¼: 
1 = æ›´æ–°tagsè‡³æœ¬åœ°æ•°æ®åº“
2 = åŸºäºæœ¬åœ°æ•°æ®åº“è¿›è¡Œæ’ç”»æœç´¢
3 = å‘æœ¬åœ°æ•°æ®åº“æäº¤å†å²è¿è¡Œæ—¶å¤‡ä»½çš„æœ‰æ•ˆæ•°æ®(åœ¨ç¨‹åºæŠ¥é”™æ—¶ä½¿ç”¨)
4 = é€€å‡º
"""
reserve_words = {'help': '_help()', 'exit': '_exit()',
                 'search': '_search()', 'list': '_list()', 'hot': '_hot()',
                 'debug': '_debug()'}
help_text = """
è¿™æ˜¯äº¤äº’æ¨¡å¼çš„ä½¿ç”¨è¯´æ˜
`help`: æ˜¾ç¤ºå¸®åŠ©
`exit`: é€€å‡ºä¸»ç¨‹åº
`search`: æœç´¢tags
`list`: åˆ—å‡ºæ‰€æœ‰tags(å±é™©æ“ä½œ)
`hot`: åˆ—å‡ºå‡ºç°æœ€å¤šçš„tags
"""

# æ—¥å¿—åˆå§‹åŒ–
logger = logging.getLogger('logger')
handler = logging.StreamHandler()
logger.setLevel(logging.DEBUG)
handler.setLevel(logging.DEBUG)
formatter = logging.Formatter(
    "[%(asctime)s %(name)s %(thread)d %(funcName)s] %(levelname)s %(message)s")
handler.setFormatter(formatter)
logger.addHandler(handler)

# Toaståˆå§‹åŒ–
toaster = ToastNotifier()

# æ•°æ®åº“åˆå§‹åŒ–
with sqlite3.connect(SQLPATH) as conn:
    cursor = conn.cursor()  

    # ä½œå“ä¸»è¡¨
    cursor.execute('''
    CREATE TABLE IF NOT EXISTS illusts (
        pid INTEGER PRIMARY KEY,
        author_id INTEGER,
        title TEXT,
        created_at TEXT DEFAULT (datetime('now', 'localtime')),
        is_private INTEGER DEFAULT 0
    )''')

    # æ ‡ç­¾å­—å…¸è¡¨
    cursor.execute('''
    CREATE TABLE IF NOT EXISTS tags (
        tag_id INTEGER PRIMARY KEY AUTOINCREMENT,
        jptag TEXT UNIQUE,
        transtag TEXT
    )''')

    # ä½œå“-æ ‡ç­¾å…³è”è¡¨
    cursor.execute('''
    CREATE TABLE IF NOT EXISTS illust_tags (
        pid INTEGER,
        tag_id INTEGER,
        FOREIGN KEY(pid) REFERENCES illusts(pid),
        FOREIGN KEY(tag_id) REFERENCES tags(tag_id),
        UNIQUE(pid, tag_id)
    )''')

    # åˆ›å»ºç´¢å¼•
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_jptag ON tags(jptag)')
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_transtag ON tags(transtag)')
    conn.commit()
    cursor.close()




def handle_exception(logger: logging.Logger, func_name: str = None, in_bar = True, async_ = False):
    """å¯¹æŠ›å‡ºé”™è¯¯çš„é€šç”¨å¤„ç†

    Args:
        logger (logging.Logger): logger
        func_name (str, optional): æŠ›å‡ºé”™è¯¯çš„å‡½æ•°å(é…åˆvar_check()ä½¿ç”¨). Defaults to None.
        in_bar(bool, optional): åŸå‡½æ•°ä¸­æ˜¯å¦æ‰“å°è¿›åº¦æ¡(tqdm)ï¼Œé˜²æ­¢è¾“å‡ºé”™ä¹±. Defaults to True.
    """
    exc_type, exc_value, tb = sys.exc_info()
    # è·å–å®Œæ•´çš„å †æ ˆè·Ÿè¸ªä¿¡æ¯
    tb_list = traceback.format_tb(tb)
    ex = "".join(tb_list)
    
    if in_bar is True and async_ is False:
        tqdm.write(f'ERROR {exc_type.__name__}: {exc_value}')
        tqdm.write(f'ERROR {ex}')
    elif in_bar is True and async_ is True:
        async_tqdm.write(f'ERROR {exc_type.__name__}: {exc_value}')
        async_tqdm.write(f'ERROR {ex}')
    else:
        logger.error(f'{exc_type.__name__}: {exc_value}')
        logger.error(ex)

    if func_name:
        return f'ERROR {func_name}'

# è·å–cookies
def get_cookies(rtime: int, forced = False):
    """è·å–Google Chromeçš„cookies

    Args:
        rtime (int): cookieæ›´æ–°é—´éš”
        forced (bool): æ˜¯å¦å¼ºåˆ¶æ›´æ–°
    """
    # åˆ¤æ–­æ˜¯å¦éœ€è¦æ›´æ–°cookies
    logger.info('éªŒè¯cookieæœ‰æ•ˆæ€§')
    
    with open(COOKIE_TIME_PATH, 'r') as f:
        data = f.read()
        if data != '':
            modify_time = float(data)
        else:
            modify_time = 0
    relative_time = time.time() - modify_time
    
    if (relative_time < rtime and 
        relative_time > 0 and 
        forced is False):
        
        logger.info(f'æ— éœ€æ›´æ–°cookies: è·ä¸Šæ¬¡æ›´æ–° {relative_time} ç§’')
    
    else:
        logger.info(f'éœ€è¦æ›´æ–°cookies: è·ä¸Šæ¬¡æ›´æ–° {relative_time} ç§’')

        # åˆ¤æ–­Google Chromeæ˜¯å¦åœ¨è¿è¡Œï¼Œå¦‚æœåœ¨chromeè¿è¡Œæ—¶ä½¿ç”¨playwrightå°†ä¼šæŠ¥é”™
        def find_process(name):
            for proc in psutil.process_iter(['pid', 'name']):
                try:
                    if name.lower() in proc.info['name'].lower():
                        return proc
                except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                    pass
            return None

        def kill_process(name):
            proc = find_process(name)
            while proc:
                logger.info(f"æ‰¾åˆ° chrome è¿›ç¨‹ (name: {proc.info['name']}, PID: {proc.info['pid']})")
                logger.info("è¯·ç»“æŸè¿›ç¨‹ï¼Œå¦åˆ™cookiesæ— æ³•æ­£å¸¸è·å–")
                
                os.system('pause')
                proc = find_process(name)
        kill_process("chrome.exe")

        # è·å–cookies
        with sync_playwright() as p:
            browser = p.chromium.launch_persistent_context(headless=True,
                executable_path=r'C:\Program Files\Google\Chrome\Application\chrome.exe',
                user_data_dir=os.path.expanduser(
                    os.path.join(os.environ['LOCALAPPDATA'], r'Google\Chrome\User Data'))
                )
            
            with open(r'.\src\cookies.json','w') as f:
                state = {"cookies": browser.cookies('https://www.pixiv.net'), "origins": []}
                f.write(json.dumps(state))
            # å…³é—­æµè§ˆå™¨
            browser.close()
        logger.info('cookieså·²è·å–')
        
        # æ›´æ–°è·å–cookieçš„æ—¶é—´
        with open(COOKIE_TIME_PATH, "w") as f:
            f.write(str(time.time()))


# æ•°æ®åº“ç›¸å…³æ“ä½œ
db_lock = threading.Lock()
def dbexecute(query: str, params: tuple|list[tuple]=None, many=False):  
    """æ•°æ®åº“æ“ä½œ

    Args:
        query (str): sqlå‘½ä»¤
        params (tuple|list[tuple], optional): æŸ¥è¯¢å‚æ•°. Defaults to None.
        many (bool, optional): æ˜¯å¦å¯¹å¤šè¡Œæ•°æ®è¿›è¡Œæ“ä½œ,è‹¥å°†å‚æ•°è®¾ä¸ºTrue,è¯·ç¡®ä¿ä¼ å…¥çš„paramsä¸ºlist[tuple]ç±»å‹. Defaults to False.

    Returns:
        list|None: æŸ¥è¯¢ç»“æœï¼ˆè‹¥æœ‰ï¼‰
    """
    res = ''
    with db_lock:  # ç¡®ä¿åªæœ‰ä¸€ä¸ªçº¿ç¨‹å¯ä»¥æ‰§è¡Œè¿™ä¸ªå—  
        conn = sqlite3.connect(SQLPATH)  
        cursor = conn.cursor()  
        try:
            if (many is True 
                and type(params) == list 
                and all(isinstance(item, tuple) for item in params)):   # éªŒè¯list[tuple]
                cursor.executemany(query, params or ())
            elif type(params) == tuple or params is None:
                cursor.execute(query, params or ()) 
            else:
                 raise Exception("ä¼ å…¥çš„paramsç±»å‹æ ¡éªŒé”™è¯¯")
            conn.commit()  
            res = cursor.fetchall()
        except Exception:
            handle_exception(logger, inspect.currentframe().f_code.co_name)
            conn.rollback()  
        finally:  
            cursor.close()  
            conn.close()  
    if res != '':
        return res
    else:
        return None


# è·å–pixivä¸Šçš„tagså¹¶ç¿»è¯‘
class ValCheckError(Exception):  
    def __init__(self):  
        super().__init__('å‚æ•°æ ¡éªŒé”™è¯¯: ä¸Šä¸ªå‡½æ•°åœ¨æ‰§è¡Œä¸­å‡ºç°é”™è¯¯')

def var_check(*args):
    '''
    # æ£€æŸ¥ä¸Šä¸ªå‡½æ•°æ‰§è¡Œæ˜¯å¦æ­£å¸¸
    '''
    for var in args:
        if str(var)[:5] == 'ERROR':
            position = str(var).split(' ')[1]
            logger.error(f'ä¸Šä¸ªå‡½æ•°åœ¨æ‰§è¡Œä¸­å‡ºç°é”™è¯¯ æ‰€åœ¨å‡½æ•°:{position}')
            return True


def analyse_bookmarks(rest_flag=2, limit=100) -> list:
    """è§£æç”¨æˆ·bookmarksæ¥å£URL

    æ¥å£åç§°: https://www.pixiv.net/ajax/user/{UID}/illusts/bookmarks?tag={}&offset={}&limit={}&rest={}&lang={}
    
    Args:
        rest_flag (int, optional): æ’ç”»çš„å¯è§æ€§ (0=å…¬å¼€, 1=ä¸å…¬å¼€, 2=å…¨éƒ¨). Defaults to 2.
        limit (int, optional): ä¸€ä¸ªæ¥å£URLæˆªå–çš„æ’ç”»æ•°ç›®, å®æµ‹æœ€å¤§å€¼ä¸º100. Defaults to 100.

    Returns:
        list: æ¥å£URL
    """

    logger.info('æ­£åœ¨è¿è¡Œ')

    try:
        rest_dict = {0: ['show'], 1: ['hide'], 2: ['show', 'hide']}
        rest = rest_dict[rest_flag]

        # è§£æç”¨æˆ·bookmarkçš„æ’ç”»æ•°é‡
        url_show = f'https://www.pixiv.net/ajax/user/{UID}/illusts/bookmarks?tag=&offset=0&limit=1&rest=show&lang=zh'
        url_hide = f'https://www.pixiv.net/ajax/user/{UID}/illusts/bookmarks?tag=&offset=0&limit=1&rest=hide&lang=zh'

        with sync_playwright() as p:
            browser = p.chromium.launch(headless=True,executable_path=CHROME_PATH)
            context = browser.new_context(storage_state=COOKIE_PATH)
            session = context.request
            
            resp = session.get(url_show).json()
            total_show = resp['body']['total']

            resp = session.get(url_hide).json()
            total_hide = resp['body']['total']
            
            browser.close()

        logger.info(f'è§£æbookmarkså®Œæˆ, å…¬å¼€æ•°é‡: {total_show}, ä¸å…¬å¼€æ•°é‡: {total_hide}')


        # è®¡ç®—è¯·æ±‚URL
        urls = []
        for r in rest:
            if r == 'show':
                total = total_show
                k = total//limit            # æ•´æ­¥æ­¥æ•°
                l = total - k*limit + 1     # å‰©ä½™éƒ¨åˆ†å¯¹åº”çš„limit
                s = 0                       # è®¡æ•°å™¨
                while k > s:
                    urls.append(
                        f'https://www.pixiv.net/ajax/user/{UID}/illusts/bookmarks?tag=&offset={s*limit}&limit={limit}&rest=show&lang=zh')
                    s += 1
                
                urls.append(
                    f'https://www.pixiv.net/ajax/user/{UID}/illusts/bookmarks?tag=&offset={s*limit}&limit={l}&rest=show&lang=zh')
            elif r == 'hide':
                total = total_hide
                k = total//limit            # æ•´æ­¥æ­¥æ•°
                l = total - k*limit + 1     # å‰©ä½™éƒ¨åˆ†å¯¹åº”çš„limit
                s = 0                       # è®¡æ•°å™¨
                while k > s:
                    urls.append(
                        f'https://www.pixiv.net/ajax/user/{UID}/illusts/bookmarks?tag=&offset={s*limit}&limit={limit}&rest=hide&lang=zh')
                    s += 1
                
                urls.append(
                    f'https://www.pixiv.net/ajax/user/{UID}/illusts/bookmarks?tag=&offset={s*limit}&limit={l}&rest=hide&lang=zh')

        logger.info(f'è§£ææ¥å£URLå®Œæˆ, æ•°é‡: {len(urls)}')

    except Exception:
        urls = handle_exception(logger, inspect.currentframe().f_code.co_name)
    return urls


async def analyse_illusts_worker(session: playwright.async_api.APIRequestContext, 
                                 queue: asyncio.Queue, 
                                 illdatas: list,
                                 ignores: list, 
                                 pbar: async_tqdm, 
                                 retries = 5):
    while True:
        url = await queue.get()
        try:
            for attempt in range(retries):
                try:
                    resp = await session.get(url)
                    if resp.status == 429:
                        wait_time = 2 ** (attempt + 1)
                        async_tqdm.write(f"è§¦å‘é™æµ [{url}]ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                        await asyncio.sleep(wait_time)
                        continue
                    
                    resp = await resp.json()
                    illdata_ = resp['body']['works']     # ä¸€ä¸ªæ¥å£urlæ‰€è·å–åˆ°çš„æ‰€æœ‰æ’ç”»ä¿¡æ¯
                    for illdata in illdata_:
                        if illdata['isMasked'] is True:
                            ignores.append(illdata['id'])
                        else:
                            illdatas.append(illdata)    # æ±‡æ€»åˆ°ä¸»åˆ—è¡¨
                    break
                except Exception as e:
                    async_tqdm.write(f"è¯·æ±‚å¤±è´¥ [{url}]: {sys.exc_info()}")
                    await asyncio.sleep(0.5 * (attempt + 1))

            pbar.update(1)
        except Exception as e:
            async_tqdm.write(sys.exc_info())
        finally:
            queue.task_done()
    
async def analyse_illusts_main(bookmark_urls: list, max_concurrency = 3):
    """è·å–bookmarkä¸­æ¯å¼ æ’ç”»çš„æ•°æ®

    Args:
        bookmark_urls (list): ç”¨æˆ·çš„å…¨éƒ¨bookmarkçš„æ¥å£url
        max_concurrency (int, optional): é¡¾åæ€ä¹‰. Defaults to 3.

    Returns:
        list: æ¯å¼ æ’ç”»çš„æ•°æ®
    """
    logger.info('æ­£åœ¨è¿è¡Œ')
    
    illdatas = []    # åŒ…å«æ’ç”»ä¿¡æ¯çš„åˆ—è¡¨
    ignores = []     # å› æ•…æ— æ³•è·å–æ’ç”»ä¿¡æ¯çš„è®¡æ•°å™¨(ä»¥åˆ—è¡¨å½¢å¼å­˜å‚¨)

    async with async_playwright() as p:
        browser = await p.chromium.launch(
            headless=True,
            executable_path=CHROME_PATH
        )
        
        context = await browser.new_context(storage_state=COOKIE_PATH)
        session = context.request
        
        queue = asyncio.Queue()
        for url in bookmark_urls:
            await queue.put(url)
        
        with async_tqdm(total = len(bookmark_urls), desc = 'è·å–æ’ç”»ä¿¡æ¯') as pbar:
            workers = [
                asyncio.create_task(analyse_illusts_worker(session, queue, illdatas, ignores, pbar))
                for _ in range(min(max_concurrency, len(bookmark_urls)))
            ]

            await queue.join()
            for w in workers:
                w.cancel()
        await context.close()
        await browser.close()
        
    logger.info(f'æ‰€æœ‰æ’ç”»ä¿¡æ¯è·å–å®Œæˆï¼Œé•¿åº¦: {len(illdatas)} å¿½ç•¥æ•°é‡: {len(ignores)}')
    return illdatas


def commit_illust_data(illdatas: list):
    """æäº¤æ’ç”»åŸºæœ¬æ•°æ®

    Args:
        illdatas (list): æ’ç”»æ•°æ®ï¼Œç”±analyse_illustsè·å–
    """
    logger.info('æ­£åœ¨è¿è¡Œ')

    # æ’ç”»åŸºæœ¬ä¿¡æ¯ (é™¤äº†tags)
    basic_illdatas = [(int(illdata['id']),
                 int(illdata['userId']),
                 illdata['title'], 
                 int(illdata['bookmarkData']['private'])   # æ­¤æ•°æ®åŸæœ¬æ˜¯å¸ƒå°”å€¼
                 )
                for illdata in illdatas]
    
    sql = '''
    INSERT INTO illusts (pid, author_id, title, is_private) VALUES (?, ?, ?, ?)
    ON CONFLICT(pid) DO UPDATE
    SET 
        author_id = excluded.author_id,
        title = excluded.title,
        is_private = excluded.is_private;
    '''
    
    
    with sqlite3.connect(SQLPATH) as conn:
        cursor = conn.cursor()
        cursor.executemany(sql, basic_illdatas)
        
        # æ’å…¥æ’ç”»tags
        for illdata in illdatas:
            pid = int(illdata['id'])
            for tag in illdata['tags']:
                cursor.execute('INSERT OR IGNORE INTO tags (jptag) VALUES (?)', (tag,))
                # è·å–tag_id
                cursor.execute('SELECT tag_id FROM tags WHERE jptag = (?)', (tag,))
                tag_id = cursor.fetchone()[0]
                # æ’å…¥å…³è”å…³ç³»
                cursor.execute('INSERT OR IGNORE INTO illust_tags (pid, tag_id) VALUES (?, ?)', (pid, tag_id))

        conn.commit()
        cursor.close()

    logger.info('æäº¤å®Œæˆ')


async def fetch_tag(session: playwright.async_api.APIRequestContext, tag: str, retries=5) -> tuple[str, dict]:
    encoded_tag = parse.quote(tag, safe = '')
    url = f"https://www.pixiv.net/ajax/search/tags/{encoded_tag}?lang=zh"
    for attempt in range(retries):
        try:
            response = await session.get(url)
            
            if response.status == 429:
                wait_time = 2 ** (attempt + 1)
                async_tqdm.write(f"è§¦å‘é™æµ [{tag}]ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                await asyncio.sleep(wait_time)
                continue
                
            return (tag, await response.json())
            
        except Exception as e:
            async_tqdm.write(f"è¯·æ±‚å¤±è´¥ [{tag}]: {sys.exc_info()}")
            if attempt == retries - 1:  # è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°
                return (tag, {"error": sys.exc_info()})
            await asyncio.sleep(0.5 * (attempt + 1))

async def fetch_tag_worker(session: playwright.async_api.APIRequestContext, queue: asyncio.Queue, results: list, pbar: async_tqdm):
    while True:
        jptag = await queue.get()
        try:
            pbar.set_description(f"Processing {str(jptag)[:10]}...")
            result: tuple[str, dict] = await fetch_tag(session, jptag)
            results.append(result)
            pbar.update(1)
        except Exception as e:
            handle_exception(logger, inspect.currentframe().f_code.co_name, in_bar=True, async_=True)
        finally:
            queue.task_done()

async def fetch_translated_tag_main(jptags: list = [], priority: list = [], max_concurrency = 20) -> tuple[list, list]:
    """
    ## è·å–pixivä¸Šçš„tagç¿»è¯‘
    
    ### args:
    - jptags: è¦è·å–ç¿»è¯‘çš„åŸå§‹tagåˆ—è¡¨
    - priority: ç¿»è¯‘è¯­è¨€ä¼˜å…ˆçº§åˆ—è¡¨ï¼ˆä¼˜å…ˆçº§é€’å‡ï¼‰
    - max_concurrency: æœ€å¤§åç¨‹æ•°é‡
    
    ### returns:
    (tuple)åŒ…å«ä¸€ä¸ªjptag-transtagçš„å­—å…¸çš„åˆ—è¡¨ï¼Œä»¥åŠä¸€ä¸ªæœªç¿»è¯‘æˆåŠŸçš„tagçš„åˆ—è¡¨
    """
    priority = ['zh', 'en', 'zh_tw']
    logger.info('æ­£åœ¨è¿è¡Œ')
    #signature = inspect.signature(fetch_translated_tag_m)
    #for param in signature.parameters.values():
    #    if var_check(eval(param.name)) == 1:
    #        raise ValCheckError
    try:
        if jptags == []:
            # åªæ‰¾å‡ºæœªç¿»è¯‘çš„tag
            res = dbexecute('''
                        SELECT jptag FROM tags WHERE transtag is NULL
                        ''')

            jptags = [r[0] for r in res]
            logger.info(f'å·²ä»æ•°æ®åº“è·å– {len(jptags)} ä¸ªtag')
        else:   # è¿™è¡Œæœ¬æ¥ä¸ç”¨ï¼Œä¸ºäº†ä¾¿äºç†è§£å°±åŠ ä¸Šäº†ï¼Œæœ‰ä¼ å…¥è¯´æ˜æ˜¯æ­¤æ¬¡è°ƒç”¨ä¸ºé‡è¯•
            jptags = jptags
            logger.info(f'å·²ä»å‚æ•°ä¸­è·å– {len(jptags)} ä¸ªtag')
    
        async with async_playwright() as p:
            browser = await p.chromium.launch(
                headless=True,
                executable_path=CHROME_PATH
            )
            
            context = await browser.new_context(storage_state=COOKIE_PATH)
            session = context.request
            
            queue = asyncio.Queue()
            for jptag in jptags:
                await queue.put(jptag)
            
            results = []
            
            with async_tqdm(total=len(jptags), desc="é‡‡é›†è¿›åº¦") as pbar:
                workers = [
                    asyncio.create_task(fetch_tag_worker(session, queue, results, pbar))
                    for _ in range(min(max_concurrency, len(jptags)))
                ]

                await queue.join()
                
                for w in workers:
                    w.cancel()
            
            await context.close()
            await browser.close()
        
        translation_results = []
        tags_caught_exception = []
        for tag, resp in results:
            if resp['error'] is not False:
                tags_caught_exception.append(tag)
            else:
                tagTranslation = resp['body']['tagTranslation']
                transtag = ''
                if tagTranslation == []:
                    # print(tagTranslation)
                    # logger.info(f'æ— tag {tag} çš„ç¿»è¯‘')
                    result = {tag: tag}
                else:
                    trans: dict = tagTranslation[tag]  # åŒ…å«æ‰€æœ‰ç¿»è¯‘è¯­è¨€çš„dict
                    lans = trans.keys()
                    for l in priority:
                        if l in lans and trans[l] != '':
                            transtag = trans[l]
                            break
                    if transtag == '':
                        av = []
                        for available in trans.values():
                            if available != '':
                                # æ˜¯å¦æœ‰ä¸ç”¨éå†çš„æ–¹æ³•?
                                [av.append(_) for _ in trans.keys() if trans[_] == available]
                        # logger.info(f'tag {tag} æ— ç›®æ ‡è¯­è¨€çš„ç¿»è¯‘ & å¯ç”¨çš„è¯­è¨€ {av}')
                        result = {tag: tag}
                    else:
                        result = {tag: transtag}
                translation_results.append(result)
                
        return translation_results, tags_caught_exception
    except Exception as e:
        return handle_exception(logger, inspect.currentframe().f_code.co_name)

def fetch_translated_tag_gather(retries = 10):
    '''
    ## è·å–å¹¶æ•´åˆç¿»è¯‘tag
    
    ### args:
    - retries: é‡è¯•æ¬¡æ•°
    
    ### returns:
    (list)åŒ…å«ä¸€ä¸ªjptag-transtagçš„å­—å…¸çš„åˆ—è¡¨
    '''
    count = 0
    trans, not_trans = asyncio.run(fetch_translated_tag_main())
    while count < retries:
        if not_trans == []:
            break
        else:
            logger.info(f'åœ¨ç¿»è¯‘è¿‡ç¨‹ä¸­å‡ºç°äº†é”™è¯¯ï¼Œå…± {len(not_trans)} ä¸ª')
            logger.info(f'é‡è¯•...({count + 1}/{retries})')
            trans_, not_trans = asyncio.run(fetch_translated_tag_main(not_trans))
            trans.append(trans_)
        count += 1
    if not_trans != []:     # é‡è¯•åè¿˜æ˜¯æœªèƒ½è·å–
        with open(TAG_LOG_PATH, 'a', encoding = 'utf-8') as f:
            f.write(str(time.strftime("%b %d %Y %H:%M:%S", time.localtime())))
            f.write(f'è¯·æ±‚tag {not_trans}')
            f.write('\n')
        logger.warning('è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä½†ä»æœ‰éƒ¨åˆ†tagæœªèƒ½ç¿»è¯‘ï¼Œå¤±è´¥çš„ç»“æœå·²å†™å…¥log')
    logger.info(f'INFO ç¿»è¯‘å®Œæˆï¼ŒæˆåŠŸ:{len(trans)}  å¤±è´¥:{len(not_trans)}')
    return trans


def commit_translated_tags(translated_tags: list):
    """æäº¤ç¿»è¯‘åçš„tags

    Args:
        translated_tags (list): fetch_translated_tagsè·å–çš„ç¿»è¯‘åtagåˆ—è¡¨
    """
    logger.info('æ­£åœ¨è¿è¡Œ')
    jpTags_transTags = [(list(jptag_transtag.keys())[0], 
                         list(jptag_transtag.values())[0])
                        for jptag_transtag in translated_tags]  # è½¬æ¢tagç¿»è¯‘å¯¹åº”å…³ç³»ä¸ºå…ƒç»„
    with sqlite3.connect(SQLPATH) as conn:
        cursor = conn.cursor()
        cursor.executemany('UPDATE OR IGNORE tags SET transtag = ? WHERE jptag = ?', jpTags_transTags)
        cursor.execute("UPDATE tags SET transtag = NULL WHERE transtag == 'None'")
        conn.commit()
        cursor.close()
    
    logger.info('ç¿»è¯‘åçš„tagå·²æäº¤')



def write_transtags_to_db_i(tran: dict):
    '''
    `tran`: éœ€è¦æäº¤çš„tags (jp:tr)
    '''
    try:
        if tran is None:
            tqdm.write('ERROR å‚æ•°ä¸ºNoneTypeç±»å‹ï¼Œå¿½ç•¥')
        else:
            transtag = list(tran.values())[0]
            jptag = list(tran.keys())[0]
        # æ³¨æ„sqlè¯­å¥transtagç”¨åŒå¼•å·ï¼
        # å¦åˆ™æ‰§è¡Œsqlæ—¶ä¼šæœ‰syntax error
        dbexecute(
            f'''UPDATE tags SET transtag = "{transtag}" WHERE jptag = "{jptag}"''')
    except Exception as e:
        tqdm.write(sys.exc_info())
        tqdm.write(f'å‡½æ•°ä¼ å…¥å‚æ•°: {tran}')
def write_transtags_to_db_m(th_count, trans):
    """æäº¤ç¿»è¯‘åçš„tags

    Args:
        th_count (int): çº¿ç¨‹æ•°
        trans (list): åŒ…å«åŸtagä¸ç¿»è¯‘åtagå­—å…¸çš„åˆ—è¡¨é›†åˆ
    """
    logger.info('æ­£åœ¨è¿è¡Œ')
    signature = inspect.signature(write_transtags_to_db_m)
    for param in signature.parameters.values():
        if var_check(eval(param.name)) == 1:
            raise ValCheckError
    try:
        all_th = []
        logger.info(f'åˆ›å»ºçº¿ç¨‹æ± ï¼Œçº¿ç¨‹æ•°é‡: {th_count}')
        with ThreadPoolExecutor(max_workers=th_count) as pool:
            for t in trans:
                exc = pool.submit(write_transtags_to_db_i, t)
                all_th.append(exc)
            for th in tqdm(as_completed(all_th), total=len(all_th)):
                if th.exception():
                    logger.error(f'è¿è¡Œæ—¶å‡ºç°é”™è¯¯: {th.exception()}')
        logger.info('ç¿»è¯‘åçš„tagå·²æäº¤è‡³è¡¨tags')
    except Exception:
        handle_exception(logger, inspect.currentframe().f_code.co_name)


def transtag_return_i(r0):
    try:
        pid, jptag0 = r0[0], r0[1]
        jptags = eval(jptag0)
        l = [''] * len(jptags)
        for i in range(len(jptags)):
            resp = dbexecute('''
                        SELECT jptag,transtag FROM tags
                        ''')
            for r in resp:
                jptag, transtag = r
                if jptag == jptags[i]:
                    l[i] = base64.b64encode(transtag.encode('utf-8'))
        dbexecute(f'''
                    UPDATE illusts SET transtag = "{l}" WHERE pid = {pid}
                    ''')
        dbexecute(f'''
                    UPDATE illusts SET is_translated = 1 WHERE pid = {pid}
                    ''')
        # logger.debug(l)
    except Exception as e:
        handle_exception(logger, inspect.currentframe().f_code.co_name)
def transtag_return_m(th_count):
    '''
    ä¸Šä¼ ç¿»è¯‘åçš„tagsè‡³è¡¨illust
    '''
    logger.info('æ­£åœ¨è¿è¡Œ')
    signature = inspect.signature(transtag_return_m)
    for param in signature.parameters.values():
        if var_check(eval(param.name)) == 1:
            raise ValCheckError()
    try:
        logger.info(f'åˆ›å»ºçº¿ç¨‹æ± ï¼Œçº¿ç¨‹æ•°é‡: {th_count}')
        with ThreadPoolExecutor(max_workers=th_count) as pool:
            resp0 = dbexecute('SELECT pid,jptag FROM illusts')
            
            all_th = [pool.submit(transtag_return_i, r0) for r0 in resp0]
            for th in tqdm(as_completed(all_th), total=len(all_th)):
                pass
        logger.info('ç¿»è¯‘åçš„tagå·²æäº¤è‡³è¡¨illust')
    except Exception:
        handle_exception(logger, inspect.currentframe().f_code.co_name)


def mapping() -> dict:
    '''
    å°†illustè¡¨ä¸­å­˜å‚¨çš„æ•°æ®è½¬æ¢ä¸ºtagå¯¹pidçš„æ˜ å°„
    '''
    logger.info('å¼€å§‹æ„å»ºtagå¯¹pidçš„æ˜ å°„')
    res = dbexecute('SELECT pid,jptag,transtag FROM illusts')

    pid__tag = []   # pidå¯¹åº”çš„tag
    tag__pid = {}   # tagå¯¹åº”çš„pid

    def formatter(pid, string: str) -> dict:
        '''
        å°†æ•°æ®åº“ä¸­çš„transtagå€¼æ ¼å¼åŒ– \n
        å·²å¼ƒç”¨
        '''
        s = string.strip('"').replace('\\', '').replace('\"', '"').strip()
        matches = re.findall(r'"([^"]+?)"', s)
        return {pid: matches}
    for r in res:
        transtag_base64 = eval(r[2])
        transtag = []
        for tag_base64 in transtag_base64:
            tag = base64.b64decode(tag_base64).decode('utf-8')
            transtag.append(tag)
        
        pid__tag.append({r[0]: eval(r[1])})
        pid__tag.append({r[0]: transtag})

    logger.info(f'ä»æ•°æ®åº“è·å–çš„æ•°æ®è§£æå®Œæˆï¼Œå…±æœ‰ {len(pid__tag) // 2} ä¸ªpid')

    for p in pid__tag:
        for key, value_list in p.items():
            for value in value_list:
                if value in tag__pid:
                    # å¦‚æœå€¼å·²ç»å­˜åœ¨ï¼Œå°†åŸå­—å…¸çš„é”®æ·»åŠ åˆ°è¯¥å€¼çš„åˆ—è¡¨ä¸­
                    tag__pid[value].append(key)
                else:
                    # å¦‚æœå€¼ä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„åˆ—è¡¨å¹¶æ·»åŠ åŸå­—å…¸çš„é”®
                    tag__pid[value] = [key]
    logger.info(f'æ˜ å°„æ„å»ºå®Œæˆï¼Œå…± {len(tag__pid)} å¯¹')
    
    # è¡¥å…¨ç©ºå€¼ï¼Œæ–¹ä¾¿åç»­åˆ›å»ºdataframeå¯¹è±¡
    maxlen = 0
    for t in tag__pid:
        tmp = len(tag__pid[t])
        if tmp > maxlen:
            maxlen = tmp
    for t in tag__pid:
        tmp = len(tag__pid[t])
        if tmp < maxlen:
            tag__pid[t].extend([None]*(maxlen-tmp))
    logger.info('è¡¥é½ç©ºå€¼å®Œæˆ')
    return tag__pid


def main():
    while True:
        # å¤‡ä»½å¹¶æ¸…ç©ºä¸Šæ¬¡è¿è¡Œçš„ç»“æœ(è‹¥æœ‰)
        timestamp = os.path.getmtime(CWD + '\\temp\\result').__round__(0)
        SrcModifyTime = datetime.datetime.fromtimestamp(timestamp)
        try:
            with open(CWD + '\\temp\\result', 'r', encoding = 'utf-8') as f:
                lines = f.readlines()
            if lines != []:
                logger.info('å¤‡ä»½ä¸Šæ¬¡è¿è¡Œæ—¶fetch_translated_tag_iå‡½æ•°çš„è¿”å›å€¼')

                shutil.copy(CWD + '\\temp\\result', CWD + '\\temp\\history\\' + str(SrcModifyTime).replace(':','-'))

                with open(CWD + '\\temp\\result', 'w', encoding = 'utf-8') as f:
                    f.write('')
        except UnicodeDecodeError:
            logger.error("è¯»å–æ–‡ä»¶æ—¶é‡åˆ°ç¼–ç é”™è¯¯")
            logger.info("ç›´æ¥å¤åˆ¶æ–‡ä»¶")
            shutil.copy(CWD + '\\temp\\result', CWD + '\\temp\\history\\' + str(SrcModifyTime).replace(':','-'))

        print(mode_select)
        mode = input('æ¨¡å¼ = ')
        if mode == '1':
            start = time.time()
            get_cookies(rtime=COOKIE_EXPIRED_TIME)
            URLs = analyse_bookmarks()
            
            # debug:
            # URLs = ['https://www.pixiv.net/ajax/user/71963925/illusts/bookmarks?tag=&offset=187&limit=1&rest=hide']

            
            illdatas = asyncio.run(analyse_illusts_main(URLs))

            # debug:
            #illdata = [{'id': '79862254', 'title': 'ã‚¿ã‚·ãƒ¥ã‚±ãƒ³ãƒˆâ™¡', 'illustType': 0, 'xRestrict': 0, 'restrict': 0, 'sl': 2, 'url': 'https://i.pximg.net/c/250x250_80_a2/img-master/img/2020/03/03/09/31/57/79862254_p0_square1200.jpg', 'description': '', 'tags': ['ã‚¿ã‚·ãƒ¥ã‚±ãƒ³ãƒˆ', 'ã‚¢ã‚ºãƒ¼ãƒ«ãƒ¬ãƒ¼ãƒ³', 'ã‚¿ã‚·ãƒ¥ã‚±ãƒ³ãƒˆ(ã‚¢ã‚ºãƒ¼ãƒ«ãƒ¬ãƒ¼ãƒ³)', 'ã‚¤ãƒ©ã‚¹ãƒˆ', 'é¯›ç„¼ã', 'ã‚¢ã‚ºãƒ¼ãƒ«ãƒ¬ãƒ¼ãƒ³10000userså…¥ã‚Š'], 'userId': '9216952', 'userName': 'AppleCaramel', 'width': 1800, 'height': 2546, 'pageCount': 1, 'isBookmarkable': True, 'bookmarkData': {'id': '25192310391', 'private': False}, 'alt': '#ã‚¿ã‚·ãƒ¥ã‚±ãƒ³ãƒˆ ã‚¿ã‚·ãƒ¥ã‚±ãƒ³ãƒˆâ™¡ - AppleCaramelçš„æ’ç”»', 'titleCaptionTranslation': {'workTitle': None, 'workCaption': None}, 'createDate': '2020-03-03T09:31:57+09:00', 'updateDate': '2020-03-03T09:31:57+09:00', 'isUnlisted': False, 'isMasked': False, 'aiType': 0, 'profileImageUrl': 'https://i.pximg.net/user-profile/img/2022/10/24/02/12/49/23505973_7d9aa88560c5115b85cc29749ed40e28_50.jpg'},
            #{'id': '117717637', 'title': 'ãŠã—ã”ã¨çµ‚ã‚ã‚Šã«ãƒã‚°ã—ã¦ãã‚Œã‚‹å¤©ä½¿', 'illustType': 0, 'xRestrict': 0, 'restrict': 0, 'sl': 4, 'url': 'https://i.pximg.net/c/250x250_80_a2/custom-thumb/img/2024/04/10/17/30/02/117717637_p0_custom1200.jpg', 'description': '', 'tags': ['ã‚ªãƒªã‚¸ãƒŠãƒ«', 'å¥³ã®å­', 'ç·‘é«ª', 'å¤©ä½¿', 'ãƒã‚°', 'å·¨ä¹³', 'ã±ã‚“ã¤', 'ã‚ªãƒªã‚¸ãƒŠãƒ«1000userså…¥ã‚Š'], 'userId': '29164302', 'userName': 'ç·‘é¢¨ãƒãƒ«ãƒˆğŸŒ¿', 'width': 1296, 'height': 1812, 'pageCount': 1, 'isBookmarkable': True, 'bookmarkData': {'id': '25109862018', 'private': False}, 'alt': '#ã‚ªãƒªã‚¸ãƒŠãƒ« ãŠã—ã”ã¨çµ‚ã‚ã‚Šã«ãƒã‚°ã—ã¦ãã‚Œã‚‹å¤©ä½¿ - ç·‘é¢¨ãƒãƒ«ãƒˆğŸŒ¿çš„æ’ç”»', 'titleCaptionTranslation': {'workTitle': None, 'workCaption': None}, 'createDate': '2024-04-10T17:30:02+09:00', 'updateDate': '2024-04-10T17:30:02+09:00', 'isUnlisted': False, 'isMasked': False, 'aiType': 1, 'profileImageUrl': 'https://i.pximg.net/user-profile/img/2024/01/25/15/56/10/25434619_c70d86172914664ea2b15cec94bc0afd_50.png'},
            #{'id': '84450882', 'title': 'ãƒã‚³è€³å¢¨ã¡ã‚ƒã‚“ğŸˆ', 'illustType': 0, 'xRestrict': 0, 'restrict': 0, 'sl': 2, 'url': 'https://i.pximg.net/c/250x250_80_a2/img-master/img/2020/09/18/19/44/35/84450882_p0_square1200.jpg', 'description': '', 'tags': ['å½¼å¥³ã€ãŠå€Ÿã‚Šã—ã¾ã™', 'ã‹ã®ã‹ã‚Š', 'æ¡œæ²¢å¢¨', 'çŒ«', 'çŒ«è€³', 'åˆ¶æœ', 'ç™½ãƒ‹ãƒ¼ã‚½', 'æ‹¾ã£ã¦ãã ã•ã„', 'å½¼å¥³ã€ãŠå€Ÿã‚Šã—ã¾ã™5000userså…¥ã‚Š'], 'userId': '38436050', 'userName': 'ã‚†ãã†ãªãï¼ åœŸæ›œæ±ã‚¹88a', 'width': 2894, 'height': 4093, 'pageCount': 1, 'isBookmarkable': True, 'bookmarkData': {'id': '24948220443', 'private': False}, 'alt': '#å½¼å¥³ã€ãŠå€Ÿã‚Šã—ã¾ã™ ãƒã‚³è€³å¢¨ã¡ã‚ƒã‚“ğŸˆ - ã‚†ãã†ãªãï¼ åœŸæ›œæ±ã‚¹88açš„æ’ç”»', 'titleCaptionTranslation': {'workTitle': None, 'workCaption': None}, 'createDate': '2020-09-18T19:44:35+09:00', 'updateDate': '2020-09-18T19:44:35+09:00', 'isUnlisted': False, 'isMasked': False, 'aiType': 0, 'profileImageUrl': 'https://i.pximg.net/user-profile/img/2020/02/22/00/11/25/17966339_a51ca7e8a3aca581fc87021488e21479_50.jpg'},
            #]


            commit_illust_data(illdatas)


            trans = fetch_translated_tag_gather()
            # debug:
            # trans = [{'ã‚ªãƒªã‚¸ãƒŠãƒ«': 'åŸåˆ›'}, {'æ‹¾ã£ã¦ãã ã•ã„': 'None'}, {'é¯›ç„¼ã': 'None'}, {'ã‹ã®ã‹ã‚Š': 'Rent-A-Girlfriend'}, {'å½¼å¥³ã€ãŠå€Ÿã‚Šã—ã¾ã™5000userså…¥ã‚Š': 'ç§Ÿå€Ÿå¥³å‹5000æ”¶è—'}, {'å¥³ã®å­': 'å¥³å­©å­'}, {'æ¡œæ²¢å¢¨': 'æ¨±æ³½å¢¨'}, {'ç·‘é«ª': 'green hair'}, {'çŒ«è€³': 'cat ears'}, {'çŒ«': 'cat'}, {'å¤©ä½¿': 'angel'}, {'ç™½ãƒ‹ãƒ¼ã‚½': 'ç™½è‰²è¿‡è†è¢œ'}, {'åˆ¶æœ': 'uniform'}, {'å½¼å¥³ã€ãŠå€Ÿã‚Šã—ã¾ã™': 'Rent-A-Girlfriend'}, {'ã‚¢ã‚ºãƒ¼ãƒ«ãƒ¬ãƒ¼ãƒ³': 'ç¢§è“èˆªçº¿'}, {'ã±ã‚“ã¤': 'èƒ–æ¬¡'}, {'ã‚ªãƒªã‚¸ãƒŠãƒ«1000userså…¥ã‚Š': 'åŸåˆ›1000usersåŠ å…¥ä¹¦ç±¤'}, {'ã‚¿ã‚·ãƒ¥ã‚±ãƒ³ãƒˆ': 'å¡”ä»€å¹²'}, {'ãƒã‚°': 'æ‹¥æŠ±'}, {'ã‚¿ã‚·ãƒ¥ã‚±ãƒ³ãƒˆ(ã‚¢ã‚ºãƒ¼ãƒ«ãƒ¬ãƒ¼ãƒ³)': 'å¡”ä»€å¹²ï¼ˆç¢§è“èˆªçº¿ï¼‰'}, {'ã‚¢ã‚ºãƒ¼ãƒ«ãƒ¬ãƒ¼ãƒ³10000userså…¥ã‚Š': 'ç¢§è“èˆªçº¿10000æ”¶è—'}, {'å·¨ä¹³': 'large breasts'}, {'ã‚¤ãƒ©ã‚¹ãƒˆ': 'æ’ç”»'}]


            commit_translated_tags(trans)

            transtag_return_m(TRANSTAG_RETURN_THREADS)
            end = time.time()
            toaster.show_toast('PixivTags', 'å·²æ›´æ–°tagsè‡³æœ¬åœ°æ•°æ®åº“', duration = 10)
            logger.info(f'æ€»è€—æ—¶: {end-start} ç§’')
        elif mode == '2':
            map_result = mapping()
            df = pd.DataFrame(map_result)
            logger.info('æ•°æ®æ“ä½œå…¨éƒ¨å®Œæˆ')
            logger.info('è¿›å…¥äº¤äº’æ¨¡å¼')
            
            # äº¤äº’æ¨¡å¼ç›¸å…³å‡½æ•°
            def _help():
                print(help_text)
            def _search():
                key = ''
                while key == '':
                    print('å‚æ•°: -f å¼ºåˆ¶æœç´¢æ­¤tag [-f tag]')
                    print('å‚æ•°: -c å¤štagæœç´¢ [-c tag0 tag1 tag2]')
                    print('è¾“å…¥å…³é”®è¯ä»¥è¿›è¡ŒæŸ¥è¯¢ï¼ˆåªæ”¯æŒå•ä¸ªå‚æ•°ï¼‰:')
                    cmd_key = input()

                    keys = list(map_result.keys())
                    if len(cmd_key.split(' ')) == 1:
                        key = cmd_key
                        target_keys = get_close_matches(key, keys, n=3, cutoff=0.5)
                        
                        print(f'å¯èƒ½çš„ç»“æœ: {target_keys}')
                        try:
                            target_key_index = int(input('è¾“å…¥å…ƒç´ ç´¢å¼•: '))
                            print(f'pids: {set(list(df[target_keys[target_key_index]].dropna().astype(int).sort_values(ascending = False)))}')

                        except Exception as e:
                            handle_exception(logger)
                            continue

                    elif cmd_key.split(' ')[0] == '-f':
                        key = cmd_key.split(' ')[-1]
                        try:
                            print(f'pids: {set(list(df[key].dropna().astype(int).sort_values(ascending = False)))}')
                        except Exception:
                            handle_exception(logger)
                    elif cmd_key.split(' ')[0] == '-c':
                        plist = []      # å­˜æ”¾æ¯æ¬¡æŸ¥è¯¢è¿”å›çš„ç»“æœé›†åˆ
                        intersection = []   # å–å¾—çš„äº¤é›†
                        
                        keylist = cmd_key.split(' ')[1:]
                        
                        s = 1
                        l = len(keylist)
                        for k in keylist:
                            while True:
                                print(f'æ­£åœ¨æŸ¥è¯¢çš„keyä¸ºç¬¬ {s} ä¸ª, å…± {l} ä¸ª')
                                target_keys = get_close_matches(k, keys, n=3, cutoff=0.5)
                                
                                print(f'å¯èƒ½çš„ç»“æœ: {target_keys}')
                                try:
                                    target_key_index = int(input('è¾“å…¥å…ƒç´ ç´¢å¼•: '))
                                    plist.extend(set(list(df[target_keys[target_key_index]].dropna().astype(int))))
                                    s += 1
                                    break
                                except Exception as e:
                                    handle_exception(logger)
                                    continue

                        for p in set(plist):
                            num = plist.count(p)
                            if num == l:
                                intersection.append(p)
                        print(f'pids: {sorted(intersection)}') 
                        key = 'done'
                    else:
                        print(f"æœªçŸ¥çš„å‚æ•°: {cmd_key.split(' ')[0]}")
            def _exit():
                logger.info('ç¨‹åºæ‰§è¡Œå®Œæˆ')
                exit()
            def _list():
                print(df)
            def _hot():
                print('è·å–çš„tagsæ•°ç›®: ')
                num = int(input())
                ser = df.count().sort_values(ascending = False).head(num)
                print(ser)
            def _debug():
                print(eval(input('python>')))
            _help()
            while True:
                print('>>>', end='')
                search = input()
                if search in reserve_words:
                    eval(reserve_words[search])
                else:
                    print('æœªçŸ¥çš„æŒ‡ä»¤')
                    _help()
                print('\n')
        elif mode == '3':
            # æ­¤æ®µä»£ç å‚è€ƒfetch_translated_tag_må‡½æ•°
            result = []
            history_file_name = input('è¾“å…¥å†å²è®°å½•æ–‡ä»¶å(ä½äº/historyç›®å½•ä¸‹ï¼Œæ ¼å¼ä¸º: xxxx-xx-xx xx-xx-xx)')
            history_file_path = CWD + '\\temp\\history\\' + history_file_name
            if os.path.exists(history_file_path):
                with open(history_file_path, 'r', encoding = 'utf-8') as f:
                    lines = f.readlines()
                    for line in lines:
                        dic = eval(line)
                        result.append(dic)
            else:
                logger.warning(f'æŒ‡å®šçš„æ–‡ä»¶ä¸å­˜åœ¨ {history_file_path}')
            
            s = 0
            for r in result:
                if r is not None:
                    r: dict
                    if list(r.keys()) == list(r.values()):
                        s += 1
            logger.info(f'tagç¿»è¯‘è·å–å®Œæˆ, å…± {len(result)} ä¸ª, æ— ç¿»è¯‘ {s} ä¸ª')
            write_transtags_to_db_m(WRITE_TRANSTAGS_TO_DB_THREADS, result)

            transtag_return_m(TRANSTAG_RETURN_THREADS)
            end = time.time()
            toaster.show_toast('PixivTags', 'å·²æ›´æ–°tagsè‡³æœ¬åœ°æ•°æ®åº“', duration = 10)
        elif mode == '4':
            logger.info('ç¨‹åºé€€å‡º')
            break
        else:
            print(f'æœªçŸ¥çš„æŒ‡ä»¤ {mode}')
        print('')

if __name__ == "__main__":
    main()